import requests
from bs4 import BeautifulSoup

print("[+] Starting CVE Scraper ...")

query = input("[-] Query to search for: ")
startIndex = input("[-] Start index at: ")

# Index list.
indexList = [
    '0',
    '20',
    '40',
    '60',
    '80',
    '100',
]
# CVE ID's.
cveIds = []
# CVE links.
cveLinks = []
# CVE description.
cveDescription = []

for item in indexList:

    # The URL we're gonna scrape.
    URL = "https://nvd.nist.gov/vuln/search/results?query=" + query + "&results_type=overview&form_type=Basic&search_type=all&startIndex=" + item
    page = requests.get(URL)

    ## Parse the page content.
    soup = BeautifulSoup(page.content, "html.parser")

    # Get all <tr> elements where CVE details are in HTML.
    results = soup.find_all('tr', attrs={'data-testid' : True})

    # Loop through all results.
    for result in results:
        # Get the CVE number.
        cve = result.find('a')
        # Add cve number to list.
        cveIds.append(cve.text)
        # Add CVE link to list.
        cveLinks.append("https://nvd.nist.gov" + cve.get("href"))

# Output the CVE ID's.
print("[+] CVE ID's ...")
print(cveIds)

# Output the CVE links.
print("[+] CVE Links ...")
print(cveLinks)

# Create list.
resultDescription = []

# Loop through CVE links.
for link in cveLinks:

    # The URL we're gonna scrape.
    page = requests.get(link)

    ## Parse the page content.
    soup = BeautifulSoup(page.content, "html.parser")

    # Get all <tr> elements where CVE details are in HTML.
    results = soup.find_all('p', attrs={'data-testid' : 'vuln-description'})

    severity = soup.find_all('a', {"id": "Cvss3NistCalculatorAnchor"})

    sevNum = []

    for sev in severity:
        sevNum.append(sev.text)

    # Output the CVE Severity.
    print("[+] CVE Severity ... ")
    print(sevNum)

    # Loop results.
    for result in results:
        # Add the description to list.
        resultDescription.append(result.text)

# Output the CVE Descriptions.
print("[+] CVE Descriptions ... ")
print(resultDescription)

# Start writing to file.
print("[+] Starting the CSV file creation ...")

# Open the file.
myfile = open('cve-scraper-results.txt', 'w')

foo = cveIds
bar = resultDescription

# Loop through ID's and Descriptions.
for f, b in zip(foo, bar):

    print(".")
    line = f + ": " + b

    myfile.write("%s\n" % line)
    
myfile.close()

# Finished writing to file.
print("[+] Finished the CSV file creation")